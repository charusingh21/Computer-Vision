{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled33.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNADxqstQfYQ"
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms, models\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision.models import vgg16\n",
        "from torchvision.models.vgg import VGG\n",
        "from sklearn.metrics import jaccard_score as jsc\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "main_dir = './image_2/'\n",
        "label_dir = './semantic/'\n",
        "\n",
        "pretrained_model = models.vgg16(pretrained = True)\n",
        "features = list(pretrained_model.features.children())\n",
        "features[0].padding=(100,100)\n",
        "\n",
        "\n",
        "class FCN16s(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:\n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "vgg_model = VGGNet(requires_grad=False)\n",
        "model = FCN16s(pretrained_net=vgg_model, n_class=35).to(device)\n",
        "input = torch.autograd.Variable(torch.randn(1, 3, 256, 1024)).to(device)\n",
        "output = model(input)\n",
        "assert output.size() == torch.Size([1, 35, 256, 1024])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, main_dir, label_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = os.listdir(main_dir)\n",
        "        all_imgs_label = os.listdir(label_dir)\n",
        "        self.total_imgs = natsorted(all_imgs)\n",
        "        self.total_imgs_label = natsorted(all_imgs_label)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        img_loc_label = os.path.join(self.label_dir, self.total_imgs_label[idx] )\n",
        "        image = Image.open(img_loc).convert('RGB')\n",
        "        labels = Image.open(img_loc_label).convert('P')\n",
        "        tensor_image = self.transform(image)\n",
        "        tensor_label = self.transform(labels)\n",
        "        return (tensor_image, (tensor_label*255).type(torch.LongTensor))\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((256,1024)),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "train_data = CustomDataset(main_dir, label_dir, transform)\n",
        "\n",
        "length_train=int(0.7*len(train_data))\n",
        "length_val= int(0.15*len(train_data))\n",
        "length_test = len(train_data) - length_train - length_val\n",
        "\n",
        "train, val, test = torch.utils.data.random_split(train_data, [length_train, length_val, length_test])\n",
        "\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False)\n",
        "validation_loader = torch.utils.data.DataLoader(val, batch_size = 1, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = 1, shuffle = False)\n",
        "\n",
        "for image, labels in training_loader:\n",
        "  print(image.size(), labels.size())\n",
        "  break\n",
        "\n",
        "# model = FCN16s().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) # fine tuned the lr\n",
        "micro = []\n",
        "macro = []\n",
        "micro_train = []\n",
        "macro_train = []\n",
        "epochs = 100\n",
        "running_loss_history = []\n",
        "val_running_loss_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "    labellist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "\n",
        "    predlist_val=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "    labellist_val=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "    running_loss = 0.0\n",
        "    val_running_loss = 0.0\n",
        "    \n",
        "    \n",
        "    for inputs, labels in training_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels[:,0])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _,preds = torch.max(outputs, dim = 1)\n",
        "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
        "        labellist=torch.cat([labellist,labels.view(-1).cpu()])\n",
        "   \n",
        "\n",
        "    else:\n",
        "      with torch.no_grad(): # we do not need gradient for validation.\n",
        "        for val_inputs, val_labels in validation_loader:\n",
        "          val_inputs = val_inputs.to(device)\n",
        "          val_labels = val_labels.to(device)\n",
        "          val_outputs = model(val_inputs)\n",
        "          val_loss = criterion(val_outputs, val_labels[:,0])\n",
        "          \n",
        "          _, val_preds = torch.max(val_outputs, 1)\n",
        "          val_running_loss += val_loss.item()\n",
        "\n",
        "          predlist_val=torch.cat([predlist_val,val_preds.view(-1).cpu()])\n",
        "          labellist_val=torch.cat([labellist_val,val_labels.view(-1).cpu()])\n",
        "\n",
        "    lbl = predlist.cpu().numpy().reshape(-1)\n",
        "    target = labellist.cpu().numpy().reshape(-1)\n",
        "    iou_micro = jsc(target, lbl, average = 'micro' )\n",
        "    iou_macro = jsc(target, lbl, average = 'macro' )\n",
        "    micro_train.append(iou_micro)\n",
        "    macro_train.append(iou_macro)\n",
        "    epoch_loss = running_loss/len(training_loader)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    val_epoch_loss = val_running_loss/len(validation_loader)\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "\n",
        "\n",
        "    lbl_val = predlist_val.cpu().numpy().reshape(-1)\n",
        "    target_val = labellist_val.cpu().numpy().reshape(-1)\n",
        "    iou_val_micro = jsc(target_val, lbl_val, average = 'micro' )\n",
        "    iou_val_macro = jsc(target_val, lbl_val, average = 'macro' )\n",
        "    micro.append(iou_val_micro)\n",
        "    macro.append(iou_val_macro)\n",
        "    print('epoch :', (e+1))       \n",
        "    print('training loss: {:.4f}, training iou(macro): {:.4f}, training iou(micro): {:.4f}'.format(epoch_loss, iou_macro, iou_micro))\n",
        "    print('validation loss: {:.4f}, validation iou(macro): {:.4f}, validation iou(micro): {:.4f}'.format(val_epoch_loss, iou_val_macro, iou_val_micro))\n",
        "\n",
        "plt.figure()\n",
        "plt.style.use('ggplot')\n",
        "plt.plot(running_loss_history, label='training loss')\n",
        "plt.plot(val_running_loss_history, label='validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('./Loss.png', dpi=256)\n",
        "\n",
        "plt.figure()\n",
        "plt.style.use('ggplot')\n",
        "#plt.plot(micro, label=' loss')\n",
        "plt.plot(micro, label='IOU Val')\n",
        "#plt.plot(micro, label=' loss')\n",
        "plt.plot(micro_train, label='IOU Train')\n",
        "plt.legend()\n",
        "plt.savefig('./IOU_micro.png', dpi=256)\n",
        "\n",
        "plt.figure()\n",
        "plt.style.use('ggplot')\n",
        "#plt.plot(micro, label=' loss')\n",
        "plt.plot(macro, label='IOU Validation')\n",
        "#plt.plot(micro, label=' loss')\n",
        "plt.plot(macro_train, label='IOU Training')\n",
        "plt.legend()\n",
        "plt.savefig('./IOU_macro.png', dpi=256)\n",
        "\n",
        "test_running_corrects = 0.0\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "labellist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "\n",
        "with torch.no_grad(): # we do not need gradient for validation.\n",
        "      for test_inputs, test_labels in test_loader:\n",
        "        test_inputs = test_inputs.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        test_outputs = model(test_inputs)\n",
        "        _, test_preds = torch.max(test_outputs, 1)\n",
        "        predlist=torch.cat([predlist,test_preds.view(-1).cpu()])\n",
        "        labellist=torch.cat([labellist,test_labels.view(-1).cpu()])\n",
        "        test_running_corrects += torch.sum(test_preds == test_labels[:,0].data)\n",
        "\n",
        "\n",
        "test_acc = test_running_corrects.float()/ (len(test_loader)*1024*256)\n",
        "print('test acc {:.4f} '.format(test_acc))\n",
        "\n",
        "from sklearn.metrics import jaccard_score as jsc\n",
        "\n",
        "lbl = predlist.cpu().numpy().reshape(-1)\n",
        "target = labellist.cpu().numpy().reshape(-1)\n",
        "print(jsc(target, lbl, average = 'micro' ))\n",
        "\n",
        "final_data = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)\n",
        "test_running_corrects = 0.0\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "labellist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "i = 0\n",
        "j = 180    #this image \n",
        "with torch.no_grad(): # we do not need gradient for validation.\n",
        "      for test_inputs, test_labels in final_data:\n",
        "        if i == j:\n",
        "          test_inputs = test_inputs.to(device)\n",
        "          test_labels = test_labels.to(device)\n",
        "          test_outputs = model(test_inputs)\n",
        "          _, test_preds = torch.max(test_outputs, 1)\n",
        "          predlist=torch.cat([predlist,test_preds.view(-1).cpu()])\n",
        "          labellist=torch.cat([labellist,test_labels.view(-1).cpu()])\n",
        "          test_running_corrects += torch.sum(test_preds == test_labels[:,0].data)\n",
        "          break\n",
        "        else:\n",
        "          i = i+1\n",
        "        \n",
        "\n",
        "from sklearn.metrics import jaccard_score as jsc\n",
        "\n",
        "lbl = predlist.cpu().numpy().reshape(-1)\n",
        "target = labellist.cpu().numpy().reshape(-1)\n",
        "print(jsc(target, lbl, average = 'micro' ))\n",
        "\n",
        "\n",
        "final_data = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)\n",
        "test_running_corrects = 0.0\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "labellist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "\n",
        "with torch.no_grad(): # we do not need gradient for validation.\n",
        "      for test_inputs, test_labels in final_data:\n",
        "        test_inputs = test_inputs.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        test_outputs = model(test_inputs)\n",
        "        _, test_preds = torch.max(test_outputs, 1)\n",
        "        predlist=torch.cat([predlist,test_preds.view(-1).cpu()])\n",
        "        labellist=torch.cat([labellist,test_labels.view(-1).cpu()])\n",
        "        test_running_corrects += torch.sum(test_preds == test_labels[:,0].data)\n",
        "        break\n",
        "\n",
        "test_acc = test_running_corrects.float()/(1024*256)\n",
        "print('test acc {:.4f} '.format(test_acc))\n",
        "\n",
        "from collections import  defaultdict\n",
        "d = defaultdict(set,\n",
        "            {-1: (0, 0, 142),\n",
        "             0: (0, 0, 0),\n",
        "             1: (0, 0, 0),\n",
        "             2: (0, 0, 0),\n",
        "             3: (0, 0, 0),\n",
        "             4: (0, 0, 0),\n",
        "             5: (111, 74, 0),\n",
        "             6: (81, 0, 81),\n",
        "             7: (128, 64, 128),\n",
        "             8: (244, 35, 232),\n",
        "             9: (250, 170, 160),\n",
        "             10: (230, 150, 140),\n",
        "             11: (70, 70, 70),\n",
        "             12: (102, 102, 156),\n",
        "             13: (190, 153, 153),\n",
        "             14: (180, 165, 180),\n",
        "             15: (150, 100, 100),\n",
        "             16: (150, 120, 90),\n",
        "             17: (153, 153, 153),\n",
        "             18: (153, 153, 153),\n",
        "             19: (250, 170, 30),\n",
        "             20: (220, 220, 0),\n",
        "             21: (107, 142, 35),\n",
        "             22: (152, 251, 152),\n",
        "             23: (70, 130, 180),\n",
        "             24: (220, 20, 60),\n",
        "             25: (255, 0, 0),\n",
        "             26: (0, 0, 142),\n",
        "             27: (0, 0, 70),\n",
        "             28: (0, 60, 100),\n",
        "             29: (0, 0, 90),\n",
        "             30: (0, 0, 110),\n",
        "             31: (0, 80, 100),\n",
        "             32: (0, 0, 230),\n",
        "             33: (119, 11, 32)})\n",
        "\n",
        "for img,lab in training_loader:\n",
        "  print(img.size())\n",
        "  break\n",
        "\n",
        "d\n",
        "\n",
        "test_preds.size()\n",
        "\n",
        "predictions = test_preds.cpu().numpy()\n",
        "predictions.shape\n",
        "\n",
        "lst = []\n",
        "p = predictions[0,:]\n",
        "for i in range(len(p)):\n",
        "  for j in range(len(p[i])):\n",
        "    lst.append((d[p[i][j]]))\n",
        "arr = np.array(lst)\n",
        "\n",
        "arr.shape\n",
        "arr = np.reshape(arr,[256,1024,3])\n",
        "\n",
        "p\n",
        "arr\n",
        "\n",
        "g = np.zeros([256,1024,3])\n",
        "for i in range(len(arr)):\n",
        "  for j in range(len(arr[i])):\n",
        "    for k in range(len(arr[i][j])):\n",
        "      g[i][j][k] = arr[i][j][k]/255.0\n",
        "\n",
        "import cv2\n",
        "cv2.imwrite('color_img.jpg',arr)\n",
        "c = cv2.imread('color_img.jpg', 1)\n",
        "c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)\n",
        "cv2.imwrite('Final_img.jpg', c)\n",
        "\n",
        "torch.save(model, \"./entire_model_fcn32_final.pt\")\n",
        "# model = torch.load('./drive/My Drive/hw5/entire_model_fcn32_final.pt')\n",
        "# model.eval()\n",
        "# t = test_preds.cpu().numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}